{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# encoding: UTF-8\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from Bio import SeqIO\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 氨基酸序列的ONE-HOT编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把一个氨基酸序列转换为一个ONE HOT二维数组。氨基酸序列长度为N，数组是N-by-21，21表示 'GAVLIPFYWSTCMNQDEKRHX'这21个氨基酸缩写字符\n",
    "def seq2OneHotArray(sequence):\n",
    "    N = len(sequence)\n",
    "    result = np.zeros(shape=(N,21),dtype=np.int32)\n",
    "    alphabet = 'GAVLIPFYWSTCMNQDEKRHX'\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    digseq = [char_to_int[char] for char in sequence]\n",
    "    for i in range(N):\n",
    "        result[i][digseq[i]] = 1\n",
    "    return result        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据序列的fasta文件构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def establishBenchmarkOneHot(fastaFile, saveFile):\n",
    "    SeqOneHot = {}\n",
    "    for seq_record in SeqIO.parse(fastaFile, 'fasta'):\n",
    "        s = seq_record.seq\n",
    "        r = seq2OneHotArray(s)\n",
    "        SeqOneHot[seq_record.name] = r\n",
    "   \n",
    "    sio.savemat(saveFile,SeqOneHot)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据binding site文件，构建数据集。按滑窗的方法，滑窗大小ws\n",
    "  - positive 是binting site序列\n",
    "  - negative 是not binding site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 滑窗，不足的以头尾循环补\n",
    "def splitWindows(ws, matFile, sitesFile, saveFile):\n",
    "    SeqOneHot = sio.loadmat(matFile)\n",
    "    X = []\n",
    "    Y = []\n",
    "    k = 0\n",
    "    t = 0\n",
    "    with open(sitesFile, 'r') as pbsreader:\n",
    "        for line in pbsreader:\n",
    "            line = line.strip()\n",
    "            if '>' in line:\n",
    "                sid = line[1:]\n",
    "                p = SeqOneHot[sid]\n",
    "                seqlen = p.shape[0]\n",
    "                col = np.size(p,1)\n",
    "                for j in range(seqlen):\n",
    "                    #create a array\n",
    "                    d = np.zeros(shape=(ws*2+1,col), dtype=np.int32)\n",
    "                    if j < ws:\n",
    "                        d[0:ws-j] = p[j-ws:]\n",
    "                        d[ws-j:2*ws+1] = p[0: ws+j+1]\n",
    "                    elif j > seqlen - ws -1:\n",
    "                        d[0:ws] = p[j-ws:j]\n",
    "                        d[ws:ws + seqlen -j] = p[j:]\n",
    "                        d[ws+seqlen-j:] = p[0:ws-seqlen+j+1]\n",
    "                    else:\n",
    "                        d[::]=p[j-ws:j+ws+1]\n",
    "                        \n",
    "                    X.insert(k,d)\n",
    "                    Y.append([1,0])\n",
    "                    k += 1\n",
    "            else:\n",
    "                sites = line.split()\n",
    "                for s in sites:\n",
    "                    idx = eval(s)\n",
    "                    Y[t + idx -1] = [0,1]\n",
    "                t=k  \n",
    "      \n",
    "    bindingsite = {}\n",
    "    negative = []\n",
    "    positive = []\n",
    "    for x,y in zip(X,Y):\n",
    "        if y[0] == 1:\n",
    "            negative.append(x)\n",
    "        else:\n",
    "            positive.append(x)\n",
    "    \n",
    "    bindingsite = {\n",
    "        'negative': negative,\n",
    "        'positive': positive\n",
    "    }\n",
    "    \n",
    "    sio.savemat(saveFile,bindingsite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对非平衡数据的处理\n",
    " - 逐步剪切并对称翻转。剪切头尾的氨基酸，以0填充，并翻转，生成新的人工数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseColumn(x):\n",
    "    temp = np.zeros((1,31,21), dtype=np.int32)\n",
    "    for i in range(21):\n",
    "        temp[0,:,i] = x[:,20-i]\n",
    "    return temp\n",
    "\n",
    "def SMote(dataset):\n",
    "    result = dataset\n",
    "    \n",
    "    k = dataset.shape[1]\n",
    "    for x in dataset:\n",
    "        result = np.append( result, reverseColumn(x),axis=0)\n",
    "        for k in range(5):\n",
    "            x[:,k] = 0\n",
    "            x[:,-(k+1)] = 0\n",
    "            result = np.append(result, [x], axis=0)\n",
    "            result = np.append( result, reverseColumn(x), axis=0)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义CNN的共享函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义权值\n",
    "def weight(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1), name='weight')\n",
    "\n",
    "#定义偏置\n",
    "def bias(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape), name='bias')\n",
    "\n",
    "#定义卷积操作\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "#定义最大池化操作\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "#定义平均池化操作\n",
    "def avg_pool_2x2(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义卷积神经网络\n",
    "  - 返回测试集预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(x_train, x_test, y_train, y_test):\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    #输入层 31-by-21\n",
    "    with tf.name_scope('input_layer'):\n",
    "        x = tf.placeholder(tf.float32, shape=[None, 32, 32, 1], name='x')\n",
    "\n",
    "    #第1个卷积层\n",
    "    with tf.name_scope('conv_1'):\n",
    "        W1 = weight([3,3,1,32])\n",
    "        b1 = bias([32])\n",
    "        conv_1 = conv2d(x, W1) + b1\n",
    "        conv_2 = tf.nn.relu(conv_1)\n",
    "\n",
    "    #第1个池化层 16-by-11\n",
    "    with tf.name_scope('pool_1'):\n",
    "        pool_1 = avg_pool_2x2(conv_1)\n",
    "\n",
    "    #第2个卷积层\n",
    "    with tf.name_scope('conv_2'):\n",
    "        W2 = weight([3,3,32,64])\n",
    "        b2 = bias([64])\n",
    "        conv_2 = conv2d(pool_1, W2) + b2\n",
    "        conv_2 = tf.nn.relu(conv_2)\n",
    "\n",
    "    #第2个池化层 8-by-6\n",
    "    with tf.name_scope(\"pool_2\"):\n",
    "        pool_2 = avg_pool_2x2(conv_2)\n",
    "\n",
    "    #第3个卷积层\n",
    "    with tf.name_scope('conv_3'):\n",
    "        W3 = weight([3,3,64,128])\n",
    "        b3 = bias([128])\n",
    "        conv_3 = conv2d(pool_2, W3) + b3\n",
    "        conv_3 = tf.nn.relu(conv_3)\n",
    "\n",
    "    #第3个池化层 4-by-3\n",
    "    with tf.name_scope('pool_3'):\n",
    "        pool_3 = avg_pool_2x2(conv_3)\n",
    "\n",
    "    #全连接层\n",
    "    with tf.name_scope('fc'):\n",
    "        #将最后一个池化层的128个通道的4-by-3的图像转换为一维向量，长度是128*4*3=1536\n",
    "        W4 = weight([1536,256]) #全连接层定义256个神经元\n",
    "        b4 = bias([256])\n",
    "        flat = tf.reshape(pool_3, [-1, 1536])\n",
    "        h = tf.nn.relu(tf.matmul(flat, W4)) + b4\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h_dropout = tf.nn.dropout(h, keep_prob)\n",
    "\n",
    "    #输出层\n",
    "    with tf.name_scope('output_layer'):\n",
    "        W5 = weight([256,2])\n",
    "        b5 = bias([2])\n",
    "        pred = tf.nn.softmax(tf.matmul(h_dropout, W5) + b5)\n",
    "    \n",
    "    #构建网络模型\n",
    "    with tf.name_scope(\"optimizer\"):\n",
    "        #定义占位符\n",
    "        y = tf.placeholder(tf.int32, shape=[None, 2], name=\"label\")\n",
    "        #定义损失函数\n",
    "        loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred,\n",
    "                                                                                 labels=y))\n",
    "        #选择优化器\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.003).minimize(loss_function)\n",
    "    \n",
    "    #定义准确率\n",
    "    with tf.name_scope(\"evalulation\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    #训练模型\n",
    "    X_TRAIN_SIZE = len(x_train)\n",
    "    TRAIN_EPOCHES = 25\n",
    "    BATCH_SIZE = 50\n",
    "    TOTAL_BATCH = int( np.ceil( X_TRAIN_SIZE / BATCH_SIZE))\n",
    "    epoch= tf.Variable(0, name='epoch', trainable=False)\n",
    "    STARTTIME = time()\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer\n",
    "        sess.run(init)\n",
    "        # 设置检查点存储目录\n",
    "        ckpt_dir = \"../log/\"\n",
    "        if not os.path.exists(ckpt_dir):\n",
    "            os.makedirs(ckpt_dir)\n",
    "        #生成saver\n",
    "        saver = tf.train.Saver(max_to_keep=5)\n",
    "        # 创建 summary_writer，用于写图文件\n",
    "        summary_writer = tf.summary.FileWriter(ckpt_dir, sess.graph)\n",
    "        # 如果有检查点文件，读取最新的检查点文件，恢复各种变量值\n",
    "        ckpt = tf.train.latest_checkpoint(ckpt_dir )\n",
    "        if ckpt != None:\n",
    "            saver.restore(sess, ckpt)     \n",
    "        else:\n",
    "            print(\"Training from scratch.\")\n",
    "\n",
    "        start_epoch= sess.run(epoch)\n",
    "        print(\"Training starts form {} epoch.\".format(start_epoch+1))\n",
    "        \n",
    "        #迭代训练\n",
    "        for ep in range(start_epoch, start_epoch + TRAIN_EPOCHES):\n",
    "            for i in range(TOTAL_BATCH):\n",
    "                start = (i * BATCH_SIZE) % X_TRAIN_SIZE\n",
    "                end = min(start + BATCH_SIZE, X_TRAIN_SIZE)\n",
    "                batch_x = x_train[start:end]\n",
    "                batch_y = y_train[start:end]\n",
    "                sess.run(optimizer,feed_dict={x: batch_x, y: batch_y, keep_prob:0.7})\n",
    "                if i % 100 == 0:\n",
    "                    print(\"Step {}\".format(i), \"finished\")\n",
    "\n",
    "            loss,acc = sess.run([loss_function,accuracy],feed_dict={x: batch_x, y: batch_y, keep_prob:0.7})\n",
    "            \n",
    "            print(\"Train epoch:\", '%02d' % (sess.run(epoch)+1), \\\n",
    "                  \"Loss=\",\"{:.6f}\".format(loss),\" Accuracy=\",acc)\n",
    "\n",
    "            #保存检查点\n",
    "            saver.save(sess,ckpt_dir+\"DBPSite_cnn_model.cpkt\",global_step=ep+1)\n",
    "\n",
    "            sess.run(epoch.assign(ep+1))\n",
    "    \n",
    "        duration =time()-STARTTIME\n",
    "        print(\"Train finished takes:\",duration)   \n",
    "    \n",
    "        #计算测试集上的预测结果\n",
    "        y_pred = sess.run(pred, feed_dict={x: x_test, y: y_test, keep_prob: 1.0})\n",
    "        \n",
    "    return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用K-Fold交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对数据集X按KFold划分训练集和测试集\n",
    "def splitByKFold(X, n=5):\n",
    "    x_trains = []\n",
    "    x_tests = []\n",
    "    kf = KFold(n_splits=n)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        x_train, x_test = X[train_index], X[test_index]\n",
    "        x_trains.append(x_train)\n",
    "        x_tests.append(x_test)\n",
    "     \n",
    "    return x_trains, x_tests\n",
    "\n",
    "def validationKFold(x_positive, x_negative, n=5):\n",
    "    x_trains_pos, x_tests_pos = splitByKFold(x_positive, n)\n",
    "    x_trains_neg, x_tests_neg = splitByKFold(x_negative, n)\n",
    "    \n",
    "    y_logists = np.ndarray((0,2))\n",
    "    y_preds = np.ndarray((0,2))\n",
    "    for i in range(n):\n",
    "        x_train_pos = x_trains_pos[i] #正类训练数据\n",
    "        x_train_neg = x_trains_neg[i] #负类训练数据\n",
    "        x_test_pos = x_tests_pos[i] #正类测试数据\n",
    "        x_test_neg = x_tests_neg[i] #负类测试数据\n",
    "        \n",
    "        x_train_pos = SMote(x_train_pos) #正类训练数据是少数类样本，进行上采样\n",
    "        \n",
    "        k_train_pos = int( len( x_train_pos)) #正类训练样本数\n",
    "        k_train_neg = int( len( x_train_neg)) #负类训练样本数\n",
    "        k_test_pos = int( len( x_test_pos)) #正类测试样本数\n",
    "        k_test_neg = int( len( x_test_neg)) #负类测试样本数\n",
    "        \n",
    "        y_train_pos = np.tile([1,0], (k_train_pos,1))\n",
    "        y_train_neg = np.tile([0,1], (k_train_neg,1))\n",
    "        y_test_pos = np.tile([1,0], (k_test_pos,1))\n",
    "        y_test_neg = np.tile([0,1], (k_test_neg,1))\n",
    "        \n",
    "        x_train = np.append(x_train_pos, x_train_neg, axis=0)\n",
    "        y_train = np.append(y_train_pos, y_train_neg, axis=0)\n",
    "        \n",
    "        x_test = np.append(x_test_pos, x_test_neg, axis=0)\n",
    "        y_test = np.append(y_test_pos, y_test_neg, axis=0)\n",
    "        \n",
    "        y_pred = cnn(x_train, x_test, y_train, y_test)\n",
    "        \n",
    "        y_logists = np.append(y_logists, y_test, axis=0)\n",
    "        y_preds = np.append(y_preds, y_pred, axis=0)\n",
    "        \n",
    "        return y_logists, y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算预测率、混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算预测的准确率\n",
    "def evalution(y_logists, y_preds):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_preds, 1),\n",
    "                                      tf.argmax(y_logists, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    with tf.Session() as sess:\n",
    "        acc = sess.run(accuracy)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "# 绘制混淆矩阵的函数\n",
    "# 参数1  cm 混淆矩阵中显示的数值 二维数组\n",
    "# 参数2 cmap 混淆矩阵中的颜色\n",
    "# 参数3 title 标题\n",
    "def plot_confusion_matrix(cm, classes, title='混淆矩阵', cmap=plt.cm.Greens):\n",
    "    # imshow() 表示绘制并显示二维图 有18个参数\n",
    "    # 参数1 X 混淆矩阵中显示的数值 二维数组\n",
    "    # 参数2 cmap 颜色 plt.cm.Blues表示蓝色 plt.cm.Reds表示红色 plt.cm.Greens表示绿色\n",
    "    # 参数5 interpolation 插值法 一般有如下值\n",
    "    #     nearest 最近邻插值法\n",
    "    #     bilinear 双线性插值法\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.imshow(cm, cmap=cmap, interpolation=\"nearest\")\n",
    "    plt.title(title)  # 标题\n",
    "    plt.colorbar()  # 显示颜色的进度条\n",
    "    tick_marks = np.arange(2)  # [0 1]\n",
    "    plt.xticks(tick_marks, classes)  # 对x轴上分类进行标记\n",
    "    plt.yticks(tick_marks, classes)  # 对y轴上分类进行标记\n",
    "\n",
    "    thresh = np.mean(cm)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(i, j, cm[j][i],\n",
    "                     horizontalalignment='center',\n",
    "                     color='white' if cm[i][j] >= thresh else 'black')\n",
    "\n",
    "    plt.xlabel('预测值')\n",
    "    plt.ylabel('真实值')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#establishBenchmarkOneHot('..\\\\data\\\\PDNA-224.fasta','..\\\\data\\\\PDNA-224-seqs-OneHot.mat')\n",
    "#splitWindows(15, '..\\\\data\\\\PDNA-224-seqs-OneHot.mat', '..\\\\data\\\\PDNA-224-binding-sites.txt', '..\\\\data\\\\PDNA-224-OneHot-15.mat')\n",
    "bindingsite = sio.loadmat('..\\\\data\\\\PDNA-224-OneHot-15.mat')\n",
    "negative_data = bindingsite['negative']\n",
    "positive_data = bindingsite['positive']\n",
    "\n",
    "y_logists, y_preds = validationKFold(positive_data, negative_data, 5)\n",
    "acc = evalution(y_logists, y_preds)\n",
    "print(\"5-Fold prediction accuracy=%.4f\" % acc)\n",
    "\n",
    "#混淆矩阵\n",
    "cnf_matrix = confusion_matrix(y_logists, y_pred)\n",
    "print(cnf_matrix)\n",
    "recall = cnf_matrix[0][0] / (cnf_matrix[0][0] + cnf_matrix[0][1])\n",
    "print('recall: ', recall)\n",
    "plot_confusion_matrix(cnf_matrix, [0, 1], cmap=plt.cm.Reds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
